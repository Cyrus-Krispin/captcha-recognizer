{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing b2z7d8ds-0.png\n",
      "CAPTCHA text: b2z7d8ds\n",
      "Filtered numbers: [25, 27, 27, 26, 23, 22, 16]\n",
      "Letter regions: 8\n",
      "Detected 8 character regions\n",
      "------\n",
      "Processing 6ad6e0-0.png\n",
      "CAPTCHA text: 6ad6e0\n",
      "Filtered numbers: [24, 24, 21, 24, 19]\n",
      "Letter regions: 6\n",
      "Detected 6 character regions\n",
      "------\n",
      "Processing upho6mjh-0.png\n",
      "CAPTCHA text: upho6mjh\n",
      "Filtered numbers: [19, 22, 17, 14, 21, 21, 6]\n",
      "Letter regions: 9\n",
      "Detected 9 character regions\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 220\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    219\u001b[0m segmenter \u001b[38;5;241m=\u001b[39m CaptchaSegmenter(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m, image_path))\n\u001b[0;32m--> 220\u001b[0m \u001b[43msegmenter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_segmentation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[20], line 206\u001b[0m, in \u001b[0;36mCaptchaSegmenter.run_segmentation\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_image()\n\u001b[1;32m    201\u001b[0m \u001b[38;5;66;03m# print(\"Applying morphological operations...\")\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;66;03m# self.apply_morphology()\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;66;03m# print(\"Finding contours...\")\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;66;03m# self.find_contours()\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;66;03m# print(\"Segmenting characters...\")\u001b[39;00m\n\u001b[0;32m--> 206\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msegment_characters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;66;03m# print(\"Segmentation completed!\")\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[20], line 174\u001b[0m, in \u001b[0;36mCaptchaSegmenter.segment_characters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    173\u001b[0m         ROI \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessed_image[y:y \u001b[38;5;241m+\u001b[39m h, x:x \u001b[38;5;241m+\u001b[39m w]\n\u001b[0;32m--> 174\u001b[0m         ROIs\u001b[38;5;241m.\u001b[39mappend((ROI, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptcha_text\u001b[49m\u001b[43m[\u001b[49m\u001b[43mchar_index\u001b[49m\u001b[43m]\u001b[49m))  \u001b[38;5;66;03m# Store ROI and corresponding character text\u001b[39;00m\n\u001b[1;32m    175\u001b[0m         char_index \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m# After collecting all ROIs, write them to disk\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "class CaptchaSegmenter:\n",
    "    def __init__(self, image_path, output_folder=\"extracted_letter_images\", min_area=10):\n",
    "        self.image_path = image_path\n",
    "        self.output_folder = output_folder\n",
    "        self.min_area = min_area\n",
    "        self.image = None\n",
    "        self.processed_image = None\n",
    "        self.contours = None\n",
    "        self.letter_regions = []\n",
    "        self.captcha_text = None\n",
    "        self.average_character_width = 0\n",
    "        \n",
    "        # Create the output folder if it doesn't exist\n",
    "        if not os.path.exists(self.output_folder):\n",
    "            os.makedirs(self.output_folder)\n",
    "\n",
    "    def load_image(self):\n",
    "        \"\"\"Loads the CAPTCHA image and converts it to grayscale.\"\"\"\n",
    "        self.image = cv2.imread(self.image_path)\n",
    "        self.image = cv2.cvtColor(self.image, cv2.COLOR_BGR2GRAY)\n",
    "        self.image = cv2.equalizeHist(self.image)\n",
    "        # plt.imshow(self.image, cmap=\"gray\")\n",
    "        # plt.show()\n",
    "        \n",
    "    def load_captcha_text_from_file_name(self):\n",
    "        \"\"\"Extracts the CAPTCHA text from the image file name.\"\"\"\n",
    "        captcha_text = os.path.basename(self.image_path).split(\".\")[0]\n",
    "        captcha_text = captcha_text.split(\"-\")[0]\n",
    "        self.captcha_text = captcha_text\n",
    "        print(f\"CAPTCHA text: {captcha_text}\")\n",
    "    \n",
    "    def preprocess_image(self):\n",
    "        \"\"\"Applies adaptive thresholding and median blur for segmentation.\"\"\"\n",
    "        # Apply adaptive thresholding to create a binary inverted image\n",
    "        im_bw_inverted = cv2.adaptiveThreshold(\n",
    "            self.image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 15, 2\n",
    "        )\n",
    "        # plt.imshow(im_bw_inverted, cmap=\"gray\")\n",
    "        # plt.show()\n",
    "\n",
    "        # Apply median blur to reduce noise\n",
    "        im_bw_inverted = cv2.medianBlur(im_bw_inverted, 3)\n",
    "\n",
    "        self.processed_image = im_bw_inverted\n",
    "        # plt.imshow(self.processed_image, cmap=\"gray\")\n",
    "        # plt.show()\n",
    "\n",
    "    def apply_morphology(self, kernel_size=(1, 1)):\n",
    "        \"\"\"Applies morphological closing to connect character parts.\"\"\"\n",
    "        kernel = np.ones(kernel_size, np.uint8)  # Adjust kernel size as needed\n",
    "        self.processed_image = cv2.morphologyEx(self.processed_image, cv2.MORPH_CLOSE, kernel)\n",
    "        # plt.imshow(self.processed_image, cmap=\"gray\")\n",
    "        # plt.show()\n",
    "\n",
    "    def find_contours(self):\n",
    "        \"\"\"Finds contours in the processed image.\"\"\"\n",
    "        self.contours = cv2.findContours(self.processed_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        self.contours = self.contours[0] if len(self.contours) == 2 else self.contours[1]\n",
    "\n",
    "    def get_character_regions_with_kernel_1(self):\n",
    "        \"\"\"Extracts character regions from the contours.\"\"\"\n",
    "        self.apply_morphology(kernel_size=(1, 1))\n",
    "        self.find_contours()\n",
    "        \n",
    "        character_widths = []\n",
    "        # Collect character widths\n",
    "        for c in self.contours:\n",
    "            area = cv2.contourArea(c)\n",
    "            if area > self.min_area:\n",
    "                (x, y, w, h) = cv2.boundingRect(c)\n",
    "                character_widths.append(w)\n",
    "\n",
    "        mean = np.mean(character_widths)\n",
    "        std_dev = np.std(character_widths)\n",
    "        threshold = mean + std_dev \n",
    "        filtered_numbers = [num for num in character_widths if num <= threshold]\n",
    "\n",
    "        print(\"Filtered numbers:\", filtered_numbers)\n",
    "        self.average_character_width = np.max(filtered_numbers) if filtered_numbers else 0\n",
    "        \n",
    "        for c in self.contours:\n",
    "            area = cv2.contourArea(c)\n",
    "            if area > self.min_area:\n",
    "                (x, y, w, h) = cv2.boundingRect(c)\n",
    "                self.letter_regions.append((x, y, w, h))\n",
    "        \n",
    "        if len(self.letter_regions) != len(self.captcha_text):\n",
    "            # skip this image if the number of detected regions is greater than the number of character\n",
    "            self.letter_regions = []\n",
    "        \n",
    "        # if len(self.letter_regions) < len(self.captcha_text):\n",
    "            # have to change kernel size maybe\n",
    "                \n",
    "\n",
    "        print(f\"Detected {len(self.letter_regions)} character regions\")\n",
    "    \n",
    "    def get_character_regions_with_kernel_2(self):\n",
    "        \"\"\"Extracts character regions from the contours.\"\"\"\n",
    "        self.apply_morphology(kernel_size=(2, 2))\n",
    "        self.find_contours()\n",
    "        \n",
    "        character_widths = []\n",
    "        # Collect character widths\n",
    "        for c in self.contours:\n",
    "            area = cv2.contourArea(c)\n",
    "            if area > self.min_area:\n",
    "                (x, y, w, h) = cv2.boundingRect(c)\n",
    "                character_widths.append(w)\n",
    "\n",
    "        mean = np.mean(character_widths)\n",
    "        std_dev = np.std(character_widths)\n",
    "        threshold = mean + std_dev \n",
    "        filtered_numbers = [num for num in character_widths if num <= threshold]\n",
    "\n",
    "        print(\"Filtered numbers:\", filtered_numbers)\n",
    "        self.average_character_width = np.max(filtered_numbers) if filtered_numbers else 0\n",
    "        \n",
    "        for c in self.contours:\n",
    "            area = cv2.contourArea(c)\n",
    "            if area > self.min_area:\n",
    "                (x, y, w, h) = cv2.boundingRect(c)\n",
    "                \n",
    "                    \n",
    "                self.letter_regions.append((x, y, w, h))\n",
    "        \n",
    "        print(\"Letter regions:\", len(self.letter_regions))\n",
    "        \n",
    "        # if len(self.letter_regions) != len(self.captcha_text):\n",
    "        #     # skip this image if the number of detected regions is greater than the number of character\n",
    "        #     self.letter_regions = []\n",
    "        \n",
    "                \n",
    "\n",
    "        print(f\"Detected {len(self.letter_regions)} character regions\")\n",
    "    \n",
    "    \n",
    "    def segment_characters(self):\n",
    "        \"\"\"Sort the detected letter images based on the x coordinate and save each character as a single image.\"\"\"\n",
    "        self.get_character_regions_with_kernel_2()\n",
    "        \n",
    "        if not self.letter_regions:\n",
    "            self.get_character_regions_with_kernel_1()\n",
    "        \n",
    "        if not self.letter_regions:\n",
    "            return\n",
    "        \n",
    "        # Sort the letter regions based on the x coordinate\n",
    "        self.letter_regions = sorted(self.letter_regions, key=lambda x: x[0])\n",
    "        \n",
    "        char_index = 0\n",
    "        ROIs = []  # List to store ROIs for all characters\n",
    "\n",
    "        # Process each character region\n",
    "        for (x, y, w, h) in self.letter_regions:\n",
    "            if w > 2 * self.average_character_width:\n",
    "                num_segments = int(round(w / self.average_character_width))\n",
    "                segment_width = w // num_segments\n",
    "                \n",
    "                for i in range(num_segments):\n",
    "                    x_segment = x + i * segment_width\n",
    "                    w_segment = segment_width if i < num_segments - 1 else (w - i * segment_width)\n",
    "                    ROI = self.processed_image[y:y + h, x_segment:x_segment + w_segment]\n",
    "                    ROIs.append((ROI, self.captcha_text[char_index]))  # Store ROI and corresponding character text\n",
    "                    char_index += 1\n",
    "            else:\n",
    "                ROI = self.processed_image[y:y + h, x:x + w]\n",
    "                ROIs.append((ROI, self.captcha_text[char_index]))  # Store ROI and corresponding character text\n",
    "                char_index += 1\n",
    "        \n",
    "        # After collecting all ROIs, write them to disk\n",
    "        if len(ROIs) != len(self.captcha_text):\n",
    "            print(\"Skipping image due to incorrect number of ROIs\")\n",
    "            self.letter_regions = []  # Clear the letter regions\n",
    "            return\n",
    "        for roi, character in ROIs:\n",
    "            output_dir = os.path.join(self.output_folder, character)\n",
    "            if not os.path.exists(output_dir):\n",
    "                os.makedirs(output_dir)\n",
    "            image_number = len(os.listdir(output_dir)) + 1\n",
    "            cv2.imwrite(os.path.join(output_dir, f\"{image_number}.png\"), roi)\n",
    "        \n",
    "        # Clear the letter regions after processing\n",
    "        self.letter_regions = []\n",
    "\n",
    "\n",
    "    def run_segmentation(self):\n",
    "        \"\"\"Runs the full segmentation process.\"\"\"\n",
    "        # print(\"Captcha text:\", self.load_captcha_text_from_file_name())\n",
    "        self.load_captcha_text_from_file_name()\n",
    "        # print(\"Loading image...\")\n",
    "        self.load_image()\n",
    "        # print(\"Preprocessing image...\")\n",
    "        self.preprocess_image()\n",
    "        # print(\"Applying morphological operations...\")\n",
    "        # self.apply_morphology()\n",
    "        # print(\"Finding contours...\")\n",
    "        # self.find_contours()\n",
    "        # print(\"Segmenting characters...\")\n",
    "        self.segment_characters()\n",
    "        # print(\"Segmentation completed!\")\n",
    "        print(\"------\")\n",
    "\n",
    "\n",
    "# image_path = \"train/a70ond9c-0.png\" \n",
    "# segmenter = CaptchaSegmenter(image_path)\n",
    "# segmenter.run_segmentation()\n",
    "\n",
    "# for all the files in the train folder\n",
    "for image_path in os.listdir(\"train\"):\n",
    "    if image_path.endswith(\".png\"):\n",
    "        print(f\"Processing {image_path}\")\n",
    "        segmenter = CaptchaSegmenter(os.path.join(\"train\", image_path))\n",
    "        segmenter.run_segmentation()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
